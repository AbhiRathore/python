# -*- coding: utf-8 -*-
"""
Created on Fri Nov 10 10:03:56 2017

@author: a612922
"""

import os,re,nltk
import pandas as pd
import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn import svm
from sklearn import cross_validation
import operator
import nltk.chunk
import cProfile
import os
path="Q:/WI/Emerging_Bus/WI_CAPS_PS_RM/RM_Analytics/a482255_Aditi/Client_Deconversion_Project/ML_TextMining/Trial_Run/"
train=pd.read_csv(path + "Phase1_Output.csv",header = 0)




def ngrams(input1, n):
  input1=input1.lower()
  row_v1 = re.sub(r'[^a-zA-Z\']', ' ', input1)
  row_v2=row_v1.rstrip()
  input1 = row_v2.split(' ')
  output = ''
  for i in range(len(input1)-n+1):
    g = '_'.join(input1[i:i+n])
    output=output+g+' '
  return output


def preprocess(text):
    row = text.lower()    
    answer_new1=''
    word_new1=''
    lemma = nltk.wordnet.WordNetLemmatizer()
    stopwords_list = open("C:/Users/a612922/Downloads/p1/stopwords.txt", "r").read().split()    

    answer_new=[]
    word_new=[]
    row_v1 = re.sub(r'[^a-zA-Z\']', ' ', row) 
    row_v2 = re.sub(' +',' ', row_v1)
    for word in row_v2.split():
        word_stem=lemma.lemmatize(word,'v')
        word_stem_new=str(lemma.lemmatize(word_stem))
        if word_stem_new not in stopwords_list:
            answer_new.append(str(word_stem_new))
            answer_new1=' '.join(answer_new)
    answer_new2 = re.sub(r'[^a-zA-Z]', " ", answer_new1)
    for word in answer_new2.split():
        if len(word)>2:
            word_new.append(word)
            word_new1=' '.join(word_new)

    return word_new1.lower()





micro=train["MicroCategory_y"].tolist()
micro = [str(s) for s in micro]
desc = train["Detail_without_sw_punct"].tolist()
desc=[str(s) for s in desc]

train_data_ci=[]
for x in range(0,len(desc)):
    if desc[x] ==  'nan': desc[x]=''
    train_data_ci.append(preprocess(desc[x])+' '+ngrams(desc[x],2)+' '+ngrams(desc[x],3))
    train_data_ci[x] = re.sub(' +',' ', train_data_ci[x])
    
    

    

train_data_micro=[]
for x in range(0,len(desc)):
    if desc[x] ==  'nan': desc[x]=''
    train_data_micro.append(preprocess(desc[x])+' '+ngrams(desc[x],2)+' '+ngrams(desc[x],3))
    
    
 #train_data_micro[x] = re.sub(' +',' ', train_data_ci[x])
    

vectorizer = TfidfVectorizer(sublinear_tf=True,analyzer = "word",tokenizer = None, preprocessor = None, max_df=0.5, stop_words = 'english') 
vectorizer = TfidfVectorizer(sublinear_tf=True,analyzer = "word",tokenizer = None,max_df=0.5,preprocessor = None,stop_words = 'english') 

    #  Training features

train_data_features_micro = vectorizer.fit_transform(train_data_micro)

tfidf_matrix1 = train_data_features_micro.toarray()

clf = svm.LinearSVC()
clf.fit(train_data_features_micro,micro)

predicted_ci = clf.predict(train_data_features_micro)


score = cross_validation.cross_val_score(clf,train_data_features_micro, y,cv=5, scoring='f1_weighted')
print("accuracy: ",score)

##



tfidf_matrix1 = train_data_features_micro.toarray()
features= vectorizer.get_feature_names()

X_dataframe = pd.DataFrame(data= tfidf_matrix1,columns=features)  

######


from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer
y = train['MicroCategory_y'].values
y = train['MicroCategory_y']


labelencoder_y = LabelEncoder()
y1= labelencoder_y.fit_transform(y)

lb_style = LabelBinarizer()
lb_results = lb_style.fit_transform(y)
y_dataframe=pd.DataFrame(lb_results, columns=lb_style.classes_)


from sklearn.cross_validation import train_test_split
from sklearn.metrics import accuracy_score
from skmultilearn.adapt import MLkNN

# 1. INSTANTIATE
enc = OneHotEncoder()

# 2. FIT
enc.fit(y1)

# 3. Transform
onehotlabels = enc.transform(y1).toarray(y1)
onehotlabels.shape



X_values = X_dataframe.iloc[:,:].values
y_values = y_dataframe.iloc[:,:].values
X_train, X_test, y_train, y_test = train_test_split(X_values,y_values, test_size = 0.25, random_state = 0)


classifier = MLkNN(k=30)
classifier.fit(X_train, y_train)
predictions = classifier.predict(X_test)
accuracy_score(y_test,predictions)




from sklearn.svm import LinearSVC
from sklearn.multiclass import OneVsRestClassifier
predictions = OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_train, y_train).predict(X_test)
accuracy_score(y_test,predictions)

####
from skmultilearn.problem_transform import BinaryRelevance
from sklearn.naive_bayes import GaussianNB
# initialize binary relevance multi-label classifier
# with a gaussian naive bayes base classifier
classifier = BinaryRelevance(GaussianNB())
# train
classifier.fit(X_train, y_train)
# predict
predictions = classifier.predict(X_test)
accuracy_score(y_test,predictions)





############

X_values = X_dataframe.iloc[:,:].values
#y_values = y_dataframe.iloc[:,:].values

y1= labelencoder_y.fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(X_values,y1, test_size = 0.25, random_state = 0)
clf = svm.LinearSVC()
clf.fit(X_train, y_train)
predicted_ci = clf.predict(X_test)
accuracy_score(y_test,predicted_ci)

predicted_ci = clf.predict(X_train)
accuracy_score(y_train,predicted_ci)




score = cross_validation.cross_val_score(clf, train_data_features_micro, y,cv=10, scoring='f1_weighted')
print("accuracy: ",score)




from catboost import CatBoostRegressor
model=CatBoostRegressor(iterations=50, depth=3, learning_rate=0.1, loss_function='RMSE')
model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_test, X_train),plot=True)

import lightgbm as lgb
train_data = lgb.Dataset(X_train, label=y_train)
test_data = lgb.Dataset(X_test,label=y_test)


param = {'num_leaves':31, 'num_trees':100, 'objective':'binary'}
param['metric'] = 'auc'
num_round = 10
bst = lgb.train(param, train_data, num_round, valid_sets=[test_data])



